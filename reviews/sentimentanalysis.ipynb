{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from pprint import pprint\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\ineso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ineso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     C:\\Users\\ineso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\ineso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\ineso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ineso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ineso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ineso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download([\"names\",\"stopwords\",\"state_union\",\"twitter_samples\",\"movie_reviews\",\"averaged_perceptron_tagger\",\"vader_lexicon\",\"punkt\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://goodreads.com/book/show/1001220.Anarch...</td>\n",
       "      <td>This collection of essays is from 1994 and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://goodreads.com/book/show/1001077.Hungar...</td>\n",
       "      <td>When I read this book, I did not know what to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://goodreads.com/book/show/1001126.Hawaii</td>\n",
       "      <td>This was good. Very extensive. Helped in plann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://goodreads.com/book/show/1001092.Compet...</td>\n",
       "      <td>No atendió mi expectativa, puede que se deba p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://goodreads.com/book/show/10011431-r101</td>\n",
       "      <td>Great book, full with construction details and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://goodreads.com/book/show/1001220.Anarch...   \n",
       "1  https://goodreads.com/book/show/1001077.Hungar...   \n",
       "2     https://goodreads.com/book/show/1001126.Hawaii   \n",
       "3  https://goodreads.com/book/show/1001092.Compet...   \n",
       "4      https://goodreads.com/book/show/10011431-r101   \n",
       "\n",
       "                                              review  \n",
       "0  This collection of essays is from 1994 and the...  \n",
       "1  When I read this book, I did not know what to ...  \n",
       "2  This was good. Very extensive. Helped in plann...  \n",
       "3  No atendió mi expectativa, puede que se deba p...  \n",
       "4  Great book, full with construction details and...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../csv/reviews_clean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in words if w.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['For', 'some', 'quick', 'analysis', ',', 'creating', 'a', 'corpus', 'could',\n",
      " 'be', 'overkill', '.', 'If', 'all', 'you', 'need', 'is', 'a', 'word', 'list',\n",
      " ',', 'there', 'are', 'simpler', 'ways', 'to', 'achieve', 'that', 'goal', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "For some quick analysis, creating a corpus could be overkill.\n",
    "If all you need is a word list,\n",
    "there are simpler ways to achieve that goal.\"\"\"\n",
    "pprint(nltk.word_tokenize(text), width=79, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words: List[str] = nltk.word_tokenize(text)\n",
    "fd = nltk.FreqDist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 2), ('a', 2), ('.', 2)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", a . \n",
      "2 2 2 \n"
     ]
    }
   ],
   "source": [
    "fd.tabulate(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_fd = nltk.FreqDist([w.lower() for w in fd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 1), ('a', 1), ('.', 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_fd.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 1079 matches:\n",
      " would want us to do . That is what America will do . So much blood has already\n",
      "ay , the entire world is looking to America for enlightened leadership to peace\n",
      "beyond any shadow of a doubt , that America will continue the fight for freedom\n",
      " to make complete victory certain , America will never become a party to any pl\n",
      "nly in law and in justice . Here in America , we have labored long and hard to \n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(nltk.corpus.state_union.words())\n",
    "text.concordance(\"america\", lines=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " would want us to do . That is what America will do . So much blood has already\n",
      "ay , the entire world is looking to America for enlightened leadership to peace\n"
     ]
    }
   ],
   "source": [
    "concordance_list = text.concordance_list(\"america\", lines=2)\n",
    "for entry in concordance_list:\n",
    "    print(entry.line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from random import shuffle\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.8012}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(\"Wow, NLTK is really powerful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_positive(tweet: str) -> bool:\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia.polarity_scores(tweet)[\"compound\"] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "negative_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "all_review_ids = positive_review_ids + negative_review_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_positive(text: str) -> bool:\n",
    "    \"\"\"True if the average of all sentence compound scores is positive.\"\"\"\n",
    "    scores = [\n",
    "        sia.polarity_scores(sentence)[\"compound\"]\n",
    "        for sentence in nltk.sent_tokenize(text)\n",
    "    ]\n",
    "    return mean(scores) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "This collection of essays is from 1994 and therefore, a lot of people in the anarchist movement might be already familiar with its ideas, in general terms.Nevertheless it's an interesting look at anarchism and its relation to the natural world, though the title itself its somewhat misleading in that the scope of the book is broader than the title implies, there are essays on anarchism's relationship with feminism and a critique of Murray Bookchin, which rehearses a few of the factionalist controversies of the time, between left and post-left, lifestyle anarchism, traditional anarcho-syndicalism, which, together with the arcane differences between sociobiology and social ecology, have always failed to hold my interest.Briefly, I can say that I come down more on the side of the seemingly more pragmatic Bookchin. The essays here presented are more engaging when they deal with more practical subjects, I found the essays on feminism, on animal rights, and on self-defense, say, more apt to command my attention than the essay on Anarchism, Chaos Theory, and the Metaphysics of Nature but, to be fair, I recognise the point being made, about self-organisation in nature, to be a valid one. One can see here, though, in places, a slight romanticism about the wilderness of the type critiqued by other writers. \n",
      "True\n",
      "When I read this book, I did not know what to expect. It's so thin to purport to be a comprehensive history of the run up to, the activities of, and the aftermath of the Hungarian Revolution of 1956. I was emotionally and intellecutally charged up by this book. It's so well written without foregoing important historical context, emperical analysis, and other observational details by someone who was on scene, but also who had close contacts/friends who were involved in the revolution. If you read this be prepared to be inspired and be jazzed up to fight! I was really moved by the descriptions of the events and how passionate and intense the revolution was. And according to the author's perspective, it was done for all the right reasons. Anderson is a very committed Marxist - to the point where nobody is immune to his critique. The final chapter is his take down of everyone - Lenin, Stalin, and Trotsky - of being obsessed with the development of a managerial class and remaining unconvinced that people could organize their own lives without managers. The big take away here is not only the strategy of communication and interaction with those who were sent to police you, but also how unnecessary leaders are to coordinate a revolution. The great point made again and again in this book is how there were no leaders - people got together and discussed what to do. There were dissenters and the like, but overall the people felt and knew what needed to be done and it was accomplished. The rise of democratic tribunals in the rural areas of Hungary was a great example of how collective democratic practice can and did work without reliance on technocrats, managers, or other defenders of the superstructure of capitalism. The Hungarians were given an inch by Kruschev, and they not only took a mile but also too the entire measurement system with them. The massive force of the Russian army was needed to make an example of them. This is a great chronicle of what happened with lots of on the ground tales of the revolution day by day. There's a lot of great analysis of the history of Soviet annexation of Eastern Europe as well as the changes in leadership that happened across the Iron Curtain before, during, and after the revolution.I loved this book so much, but it really excited me about the possibilities of actual democracy and how frightened most people are in the managerial class that we might just get it one day.\n",
      "True\n",
      "This was good. Very extensive. Helped in planning trip to Hawaii and historical places we wanted to see\n",
      "False\n",
      "No atendió mi expectativa, puede que se deba porque el libro y sus conceptos fuerons escritos de una forma de expresión tanto de crítica como incentivo sobre las fuerzas laborales de las grandes industrias de Estados Unidos para la epoca de finales de los años noventa, en especial previo a su publicación en 1996.Apoyo el concepto inicial que el libro quiere transmitir bajo la premicia que la fuerza laboral de las personas tiene una importancia muy poco valorada por la industria y aún más en la epoca de las transiciones industriales y ahora comparandolo con con el año 2021 con todo lo que se vive y se dislumbra cada vez más una precalización de los trabajos y profesiones del futuro tienen una gran incertidumbre por delante. Consideranto esto como de antecedente, creo que el libro no es tán cautivante como otros libros que leí del autor, caso te interese puedes sacarle provecho, sin embargo, una lectura más actual sin duda podría ser una mejor opción, aún así otros libros del mismo autor son facinantes sobre temas similares expuestos en este libro, podría recomendar algo mucho más reciente y vigente sobre las clases trabajadoras como lo es el Libro Dying for a Paycheck.\n",
      "True\n",
      "Great book, full with construction details and some engineering techniques.Lots of interesting pictures.\n",
      "True\n",
      "What it says on the tin. Many people know the tragic story of the Hindenburg, but the British airships are lesser known, probably due to lack of eyewitness film of the crash.The book has a good coverage of the history of the R101, the R100 and the whole spectacle of the British Airship industry, though it's not very in depth. Of course, being a pictorial history you shouldn't be looking for in depth here either.Every page has amazing photos, many of which I'd never seen before. I would love to see something along the lines of a Ken Marschall treatment similar to his books on the Titanic or the Hindenburg, but until then, this is a pretty outstanding historical reference.\n",
      "True\n",
      "This book discusses the associations between clothing and power, with a focus on Europe during the 18th, 19th, and early 20th centuries. It condenses an impressive amount of research into a short book and presents the material entertainingly and informatively. The element that was newest and most interesting to me was the rise of association between military uniforms and the monarchy in the late 18th century. It seems that pre-revolutionary France had the only European court at which military uniform could not be worn, specific court dress was still required. As well as consideration of broad trends, such as the shifts between uniform and frock coat wearing as monarchs changed, 'Dressed to Rule' is enlivened by personal anecdotes from the period. For example, a number of monarchs and members of court evidently found the elaborate nature of the clothing that had to wear rather tiresome. Nonetheless they wore it as they understood its significance. The role of the city of Lyon as a tireless promoter of fancy silk garments is also rather fascinating. As Mansel comments, perhaps this explains some of its unwillingness to welcome the French Revolution, which destroyed demand for its luxurious products? The twentieth century is covered in much less depth than the eighteenth and nineteenth, however the importance of military uniform to fascist and communist regimes is touched upon. Overall the book spends most of its time on the importance military uniforms. I would have liked to have seen a little more discussion of women's costumes, although these are mentioned at various points. Queen Victoria's mourning and Catherine the Great's uniform-gowns, for instance, are talked about. Perhaps not with quite the same respect as the male monarchs, though.This is overall an interesting book on an intriguing subject. If you have an interest in the power of clothing, especially uniforms, in European history, I recommend it.\n",
      "False\n",
      "georgian, historical, regency, royalty, victorian \n",
      "True\n",
      "While pedantic and hand-waving at times, Purchase's Anarchism and Ecology pointedly emphasizes the geographic malaise of capitalist/communist societies. Drawing on Kropotkin and the much-ignored Reclus, Purchase zeroes in on limitations imposed by the unsustainable duality between town and country, worker and farmer. To be sure, Purchase does shroud his analysis with loaded, and to some extent debatable, terminology (a Green Party involves bickering among Bourgeois parliamentarians). Similar conceptual lapses are introduced by his technical/art historical analysis of aboriginal sandpaintings rather than a more rigorous quantitative discussion that could have drawn on modern concepts of landscape planning such as network design. Yet for all these faults, Purchase manages to weave in history and modern concerns, demonstrating, much as Bookchin does, that many of the problems besetting an earlier generation of anarchist thinkers concerned about environmental problems have been overcome by technological innovation. And Purchase convincingly demonstrates that unless these discoveries are put to a liberatory use, their benefits for humanity as a whole will be challenged by their environmental recklessness.\n",
      "False\n",
      "mancows??\n"
     ]
    }
   ],
   "source": [
    "for review in reviews[:10]:\n",
    "    print(is_positive(review))\n",
    "    print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "\n",
    "def skip_unwanted(pos_tuple):\n",
    "    word, tag = pos_tuple\n",
    "    if not word.isalpha() or word in unwanted:\n",
    "        return False\n",
    "    if tag.startswith(\"NN\"):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "positive_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"pos\"]))\n",
    ")]\n",
    "negative_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"neg\"]))\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_fd = nltk.FreqDist(positive_words)\n",
    "negative_fd = nltk.FreqDist(negative_words)\n",
    "\n",
    "common_set = set(positive_fd).intersection(negative_fd)\n",
    "\n",
    "for word in common_set:\n",
    "    del positive_fd[word]\n",
    "    del negative_fd[word]\n",
    "\n",
    "top_100_positive = {word for word, count in positive_fd.most_common(100)}\n",
    "top_100_negative = {word for word, count in negative_fd.most_common(100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "\n",
    "positive_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words([\n",
    "    w for w in nltk.corpus.movie_reviews.words(categories=[\"pos\"])\n",
    "    if w.isalpha() and w not in unwanted\n",
    "])\n",
    "negative_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words([\n",
    "    w for w in nltk.corpus.movie_reviews.words(categories=[\"neg\"])\n",
    "    if w.isalpha() and w not in unwanted\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = dict()\n",
    "    wordcount = 0\n",
    "    compound_scores = list()\n",
    "    positive_scores = list()\n",
    "\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sentence):\n",
    "            if word.lower() in top_100_positive:\n",
    "                wordcount += 1\n",
    "        compound_scores.append(sia.polarity_scores(sentence)[\"compound\"])\n",
    "        positive_scores.append(sia.polarity_scores(sentence)[\"pos\"])\n",
    "\n",
    "    # Adding 1 to the final compound score to always have positive numbers\n",
    "    # since some classifiers you'll use later don't work with negative numbers.\n",
    "    features[\"mean_compound\"] = mean(compound_scores) + 1\n",
    "    features[\"mean_positive\"] = mean(positive_scores)\n",
    "    features[\"wordcount\"] = wordcount\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"pos\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "]\n",
    "features.extend([\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"neg\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               wordcount = 3                 pos : neg    =     25.2 : 1.0\n",
      "               wordcount = 5                 pos : neg    =     13.1 : 1.0\n",
      "               wordcount = 4                 pos : neg    =      5.0 : 1.0\n",
      "               wordcount = 2                 pos : neg    =      4.0 : 1.0\n",
      "               wordcount = 0                 neg : pos    =      1.7 : 1.0\n",
      "               wordcount = 1                 pos : neg    =      1.5 : 1.0\n",
      "           mean_positive = 0.05566666666666667    pos : neg    =      1.0 : 1.0\n",
      "           mean_positive = 0.08418181818181818    pos : neg    =      1.0 : 1.0\n",
      "           mean_positive = 0.08611764705882353    pos : neg    =      1.0 : 1.0\n",
      "           mean_positive = 0.09154545454545454    pos : neg    =      1.0 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6525"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count = int(len(features) * 0.8)\n",
    "shuffle(features)\n",
    "classifier = nltk.NaiveBayesClassifier.train(features[:train_count])\n",
    "classifier.show_most_informative_features(10)\n",
    "nltk.classify.accuracy(classifier, features[train_count:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import (\n",
    "    BernoulliNB,\n",
    "    ComplementNB,\n",
    "    MultinomialNB,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"MLPClassifier\": MLPClassifier(max_iter=1000),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.00% - BernoulliNB\n",
      "70.00% - ComplementNB\n",
      "70.00% - MultinomialNB\n",
      "71.25% - KNeighborsClassifier\n",
      "66.75% - DecisionTreeClassifier\n",
      "73.25% - RandomForestClassifier\n",
      "76.75% - LogisticRegression\n",
      "75.75% - MLPClassifier\n",
      "75.00% - AdaBoostClassifier\n"
     ]
    }
   ],
   "source": [
    "train_count = int(len(features) * 0.8)\n",
    "shuffle(features)\n",
    "for name, sklearn_classifier in classifiers.items():\n",
    "    classifier = nltk.classify.SklearnClassifier(sklearn_classifier)\n",
    "    classifier.train(features[:train_count])\n",
    "    accuracy = nltk.classify.accuracy(classifier, features[train_count:])\n",
    "    print(F\"{accuracy:.2%} - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.00% - MLP\n"
     ]
    }
   ],
   "source": [
    "train_count = int(len(features) * 0.8)\n",
    "shuffle(features)\n",
    "classifier = nltk.classify.SklearnClassifier(MLPClassifier(max_iter=1000))\n",
    "classifier.train(features[:train_count])\n",
    "accuracy = nltk.classify.accuracy(classifier, features[train_count:])\n",
    "print(F\"{accuracy:.2%} - {'MLP'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An excellent overview of Indian experiences in the Civil War, focusing on several tribes and individuals. Covers military experiences as well as home life, and broader effects on tribes. Some background on their histories before and after the war. Short, but detailed. \n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "review = reviews[20]\n",
    "print(review)\n",
    "print(classifier.classify(extract_features(review)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2e22e95839c9680a42a8bcab451ffc0850e7cddc76146d68d3eb9865bb1afd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
